{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2d4119-3b15-4286-afdc-cb08edda869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2fa4dca-3f16-4a7c-b8a6-797dc68d468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conso_tou = pd.read_csv(\"conso_heat_perif_toulouse\")\n",
    "conso_zur = pd.read_csv(\"conso_heat_perif_zurich\")\n",
    "conso_sev = pd.read_csv(\"conso_cool_perif_seville\")\n",
    "occ=pd.read_csv(\"Occupancy_per_hour\",delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "332c1907-36fd-4036-982f-79fdcd1eb0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    \"agen\": \"Meteo_Perif_Toulouse_Contemporain/Agen/Simulation_Outputs\",\n",
    "    \"albi\": \"Meteo_Perif_Toulouse_Contemporain/Albi/Simulation_Outputs\",\n",
    "    \"auch\": \"Meteo_Perif_Toulouse_Contemporain/Auch/Simulation_Outputs\",\n",
    "    \"toulouse\": \"Meteo_Perif_Toulouse_Contemporain/Toulouse/Simulation_Outputs\",\n",
    "    \"Birmensdorf\":\"Meteo_Perif_Zurich_Contemporain/Birmensdorf/Simulation_Outputs\",\n",
    "    \"Taenikon\":\"Meteo_Perif_Zurich_Contemporain/Taenikon/Simulation_Outputs\",\n",
    "    \"Zurich_fluntern\":\"Meteo_Perif_Zurich_Contemporain/Zuerich_Fluntern/Simulation_Outputs\",\n",
    "    \"Zurich_kloten\":\"Meteo_Perif_Zurich_Contemporain/Zuerich_kloten/Simulation_Outputs\"\n",
    "}\n",
    "\n",
    "files2 = {\n",
    "    \"Cordoba\": \"Meteo_Perif_Seville_Contemporain/Cordoba/Simulation_Outputs\",\n",
    "    \"Granada\": \"Meteo_Perif_Seville_Contemporain/Granada/Simulation_Outputs\",\n",
    "    \"Malaga\": \"Meteo_Perif_Seville_Contemporain/Malaga/Simulation_Outputs\",\n",
    "    \"Sevilla\": \"Meteo_Perif_Seville_Contemporain/Sevilla/Simulation_Outputs\"   \n",
    "}\n",
    "\n",
    "files3 = {\n",
    "    \"agen\": \"Meteo_Perif_Toulouse_Contemporain/Agen/Meteo_input\",\n",
    "    \"albi\": \"Meteo_Perif_Toulouse_Contemporain/Albi/Meteo_input\",\n",
    "    \"auch\": \"Meteo_Perif_Toulouse_Contemporain/Auch/Meteo_input\",\n",
    "    \"toulouse\": \"Meteo_Perif_Toulouse_Contemporain/Toulouse/Meteo_input\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7839ecc4-e4dd-4512-a8a7-29c84f764200",
   "metadata": {},
   "outputs": [],
   "source": [
    "for city, path in files.items():\n",
    "      globals()[f\"Text_{city}\"] = extract_columns(files[city],1)\n",
    "\n",
    "for city2, path2 in files2.items():\n",
    "      globals()[f\"Text_{city2}\"] = extract_columns(files2[city2],1)    \n",
    "\n",
    "for city3, path3 in files3.items():\n",
    "      globals()[f\"hum_{city3}\"] = extract_columns(files3[city3],3)  \n",
    "\n",
    "occupation=extract_columns(\"Occupancy_per_hour\",1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b1a895c-825c-414c-bb71-61d88cc15c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_combined_tou = pd.concat([Text_agen, Text_albi,Text_auch,Text_toulouse], axis=0).reset_index(drop=True)\n",
    "Text_combined_zur = pd.concat([Text_Birmensdorf,Text_Taenikon,Text_Zurich_fluntern,Text_Zurich_kloten], axis=0).reset_index(drop=True)\n",
    "Text_combined_sev = pd.concat([Text_Cordoba, Text_Granada,Text_Malaga,Text_Sevilla], axis=0).reset_index(drop=True)\n",
    "Text_combined_tou['clusters'] = conso_tou['clusters']\n",
    "Text_combined_tou['heat_on'] = conso_tou['heat_on']\n",
    "Text_combined_zur['clusters'] = conso_zur['clusters']\n",
    "Text_combined_zur['heat_on'] = conso_zur['heat_on']\n",
    "Text_combined_sev['clusters'] = conso_sev['clusters']\n",
    "Text_combined_sev['cool_on'] = conso_sev['cool_on']\n",
    "Text_combined_tou.columns = Text_combined_tou.columns.astype(str)\n",
    "Text_combined_zur.columns = Text_combined_zur.columns.astype(str)\n",
    "Text_combined_sev.columns = Text_combined_sev.columns.astype(str)\n",
    "\n",
    "\n",
    "Text_occ_agen = pd.concat([Text_agen,occupation],axis=1).reset_index(drop=True)\n",
    "Text_occ_albi = pd.concat([Text_albi,occupation],axis=1).reset_index(drop=True)\n",
    "Text_occ_auch = pd.concat([Text_auch,occupation],axis=1).reset_index(drop=True)\n",
    "Text_occ_toulouse = pd.concat([Text_toulouse,occupation],axis=1).reset_index(drop=True)\n",
    "Text_occ_combined_tou = pd.concat([Text_occ_agen, Text_occ_albi,Text_occ_auch,Text_occ_toulouse], axis=0).reset_index(drop=True)\n",
    "Text_occ_combined_tou['clusters'] = conso_tou['clusters']\n",
    "Text_occ_combined_tou['heat_on'] = conso_tou['heat_on']\n",
    "Text_occ_combined_tou.columns = Text_occ_combined_tou.columns.astype(str)\n",
    "\n",
    "\n",
    "Hum_combined_tou = pd.concat([hum_agen, hum_albi,hum_auch,hum_toulouse], axis=0).reset_index(drop=True)\n",
    "Hum_combined_tou['clusters'] = conso_tou['clusters']\n",
    "Hum_combined_tou['heat_on'] = conso_tou['heat_on']\n",
    "Hum_combined_tou.columns = Hum_combined_tou.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa2ac113-f070-4525-ad1f-3dcf96eb381b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>clusters</th>\n",
       "      <th>heat_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.40</td>\n",
       "      <td>10.45</td>\n",
       "      <td>10.40</td>\n",
       "      <td>10.25</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.15</td>\n",
       "      <td>10.10</td>\n",
       "      <td>10.10</td>\n",
       "      <td>10.15</td>\n",
       "      <td>10.50</td>\n",
       "      <td>...</td>\n",
       "      <td>13.70</td>\n",
       "      <td>13.10</td>\n",
       "      <td>12.60</td>\n",
       "      <td>12.25</td>\n",
       "      <td>11.95</td>\n",
       "      <td>11.60</td>\n",
       "      <td>11.25</td>\n",
       "      <td>10.90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.45</td>\n",
       "      <td>9.80</td>\n",
       "      <td>9.15</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.45</td>\n",
       "      <td>8.10</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.55</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.45</td>\n",
       "      <td>...</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.15</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.45</td>\n",
       "      <td>8.20</td>\n",
       "      <td>7.95</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.05</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.35</td>\n",
       "      <td>7.45</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.55</td>\n",
       "      <td>7.60</td>\n",
       "      <td>7.85</td>\n",
       "      <td>...</td>\n",
       "      <td>12.20</td>\n",
       "      <td>11.65</td>\n",
       "      <td>11.10</td>\n",
       "      <td>10.70</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.80</td>\n",
       "      <td>9.35</td>\n",
       "      <td>8.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.30</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.35</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.25</td>\n",
       "      <td>5.95</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.85</td>\n",
       "      <td>9.20</td>\n",
       "      <td>8.45</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.10</td>\n",
       "      <td>6.45</td>\n",
       "      <td>5.80</td>\n",
       "      <td>5.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.55</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.45</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>11.10</td>\n",
       "      <td>9.70</td>\n",
       "      <td>8.65</td>\n",
       "      <td>8.10</td>\n",
       "      <td>7.55</td>\n",
       "      <td>7.05</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>-3.25</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>-3.45</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-3.55</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>-1.55</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>6.10</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>3.60</td>\n",
       "      <td>3.15</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>7.95</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.35</td>\n",
       "      <td>6.30</td>\n",
       "      <td>6.30</td>\n",
       "      <td>6.25</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>6.25</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.80</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.05</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.55</td>\n",
       "      <td>...</td>\n",
       "      <td>10.45</td>\n",
       "      <td>10.05</td>\n",
       "      <td>9.45</td>\n",
       "      <td>9.20</td>\n",
       "      <td>9.20</td>\n",
       "      <td>8.95</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>7.80</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.25</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.15</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      9  \\\n",
       "0     10.40  10.45  10.40  10.25  10.20  10.15  10.10  10.10  10.15  10.50   \n",
       "1     10.45   9.80   9.15   8.75   8.45   8.10   7.80   7.55   7.40   7.45   \n",
       "2      7.05   7.30   7.30   7.30   7.35   7.45   7.50   7.55   7.60   7.85   \n",
       "3      8.30   8.00   7.35   6.85   6.55   6.25   5.95   5.70   5.60   6.00   \n",
       "4      4.55   4.00   3.45   3.05   2.75   2.45   2.25   2.10   2.00   3.00   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1455  -3.25  -3.25  -3.30  -3.35  -3.45  -3.50  -3.55  -3.60  -3.60  -3.00   \n",
       "1456  -1.55  -1.40  -1.25  -1.15  -1.05  -0.95  -0.85  -0.75  -0.65   0.15   \n",
       "1457   3.60   3.15   2.70   2.40   2.15   1.90   1.70   1.50   1.45   2.20   \n",
       "1458   6.25   6.40   6.55   6.65   6.80   6.95   7.05   7.15   7.20   7.55   \n",
       "1459   7.80   6.95   6.00   5.25   4.70   4.15   3.65   3.20   2.95   3.00   \n",
       "\n",
       "      ...     16     17     18     19     20     21     22     23  clusters  \\\n",
       "0     ...  13.70  13.10  12.60  12.25  11.95  11.60  11.25  10.90       2.0   \n",
       "1     ...   9.60   9.15   8.75   8.45   8.20   7.95   7.65   7.15       2.0   \n",
       "2     ...  12.20  11.65  11.10  10.70  10.30   9.80   9.35   8.75       2.0   \n",
       "3     ...   9.85   9.20   8.45   7.75   7.10   6.45   5.80   5.15       1.0   \n",
       "4     ...  11.10   9.70   8.65   8.10   7.55   7.05   6.50   5.95       2.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...       ...   \n",
       "1455  ...   1.10   0.30  -0.30  -0.55  -0.80  -1.00  -1.20  -1.45       1.0   \n",
       "1456  ...   6.10   5.20   4.60   4.45   4.30   4.15   4.00   3.85       1.0   \n",
       "1457  ...   7.95   7.00   6.35   6.30   6.30   6.25   6.20   6.20       2.0   \n",
       "1458  ...  10.45  10.05   9.45   9.20   9.20   8.95   8.60   8.30       2.0   \n",
       "1459  ...   3.00   2.55   2.25   1.95   1.55   1.15   0.70   0.30       1.0   \n",
       "\n",
       "      heat_on  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "1455        1  \n",
       "1456        1  \n",
       "1457        1  \n",
       "1458        1  \n",
       "1459        1  \n",
       "\n",
       "[1460 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_combined_tou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a54797-5554-4a3a-b777-0daf084e1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "X=Text_combined_tou.drop(columns=[\"clusters\"])\n",
    "y=Text_combined_tou[\"clusters\"]\n",
    "X_scaled=standardize_data(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41927aa8-bfe4-4a6d-8c8b-7b48da9cfbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1))) / (tf.reduce_sum(tf.round(tf.clip_by_value(y_pred, 0, 1))) + tf.keras.backend.epsilon())\n",
    "    recall = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1))) / (tf.reduce_sum(tf.round(tf.clip_by_value(y_true, 0, 1))) + tf.keras.backend.epsilon())\n",
    "    return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b04bb98-325f-4d8a-b00e-4db82f57006c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,120</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,260</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)                 │           \u001b[38;5;34m3,120\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)                  │           \u001b[38;5;34m7,260\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m244\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,624</span> (41.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,624\u001b[0m (41.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,624</span> (41.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,624\u001b[0m (41.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=120, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=60, activation='relu'))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be76e886-cec7-4da0-8174-ebcd15dd1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3119731a-9932-4eb7-ba8c-e9fc15ad0f07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8996 - f1_score: 0.9027 - loss: 0.2167 - val_accuracy: 0.8699 - val_f1_score: 0.8751 - val_loss: 0.2495\n",
      "Epoch 2/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8933 - f1_score: 0.8940 - loss: 0.2295 - val_accuracy: 0.8664 - val_f1_score: 0.8820 - val_loss: 0.2392\n",
      "Epoch 3/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8999 - f1_score: 0.9054 - loss: 0.2136 - val_accuracy: 0.8596 - val_f1_score: 0.8770 - val_loss: 0.2473\n",
      "Epoch 4/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8887 - f1_score: 0.8916 - loss: 0.2197 - val_accuracy: 0.8664 - val_f1_score: 0.8820 - val_loss: 0.2385\n",
      "Epoch 5/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9101 - f1_score: 0.9114 - loss: 0.2023 - val_accuracy: 0.8630 - val_f1_score: 0.8757 - val_loss: 0.2418\n",
      "Epoch 6/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9053 - f1_score: 0.9075 - loss: 0.2154 - val_accuracy: 0.8699 - val_f1_score: 0.8771 - val_loss: 0.2486\n",
      "Epoch 7/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9154 - f1_score: 0.9156 - loss: 0.1977 - val_accuracy: 0.8562 - val_f1_score: 0.8707 - val_loss: 0.2551\n",
      "Epoch 8/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8960 - f1_score: 0.8942 - loss: 0.2341 - val_accuracy: 0.8390 - val_f1_score: 0.8586 - val_loss: 0.2673\n",
      "Epoch 9/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8888 - f1_score: 0.8862 - loss: 0.2411 - val_accuracy: 0.8664 - val_f1_score: 0.8810 - val_loss: 0.2410\n",
      "Epoch 10/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8906 - f1_score: 0.8919 - loss: 0.2319 - val_accuracy: 0.8699 - val_f1_score: 0.8806 - val_loss: 0.2414\n",
      "Epoch 11/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8989 - f1_score: 0.9057 - loss: 0.2094 - val_accuracy: 0.8836 - val_f1_score: 0.8944 - val_loss: 0.2397\n",
      "Epoch 12/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8785 - f1_score: 0.8801 - loss: 0.2490 - val_accuracy: 0.8801 - val_f1_score: 0.8949 - val_loss: 0.2365\n",
      "Epoch 13/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8902 - f1_score: 0.8914 - loss: 0.2358 - val_accuracy: 0.8767 - val_f1_score: 0.8885 - val_loss: 0.2441\n",
      "Epoch 14/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8989 - f1_score: 0.8990 - loss: 0.2174 - val_accuracy: 0.8836 - val_f1_score: 0.8948 - val_loss: 0.2423\n",
      "Epoch 15/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8928 - f1_score: 0.8899 - loss: 0.2378 - val_accuracy: 0.8664 - val_f1_score: 0.8762 - val_loss: 0.2420\n",
      "Epoch 16/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9054 - f1_score: 0.9158 - loss: 0.2120 - val_accuracy: 0.8836 - val_f1_score: 0.8935 - val_loss: 0.2388\n",
      "Epoch 17/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9127 - f1_score: 0.9141 - loss: 0.1961 - val_accuracy: 0.8801 - val_f1_score: 0.8903 - val_loss: 0.2405\n",
      "Epoch 18/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9117 - f1_score: 0.9090 - loss: 0.1931 - val_accuracy: 0.8801 - val_f1_score: 0.8917 - val_loss: 0.2380\n",
      "Epoch 19/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9046 - f1_score: 0.9108 - loss: 0.2125 - val_accuracy: 0.8664 - val_f1_score: 0.8686 - val_loss: 0.2632\n",
      "Epoch 20/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9070 - f1_score: 0.9085 - loss: 0.2228 - val_accuracy: 0.8630 - val_f1_score: 0.8759 - val_loss: 0.2546\n",
      "Epoch 21/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8908 - f1_score: 0.8950 - loss: 0.2256 - val_accuracy: 0.8767 - val_f1_score: 0.8884 - val_loss: 0.2497\n",
      "Epoch 22/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9041 - f1_score: 0.9069 - loss: 0.2127 - val_accuracy: 0.8973 - val_f1_score: 0.9059 - val_loss: 0.2397\n",
      "Epoch 23/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9070 - f1_score: 0.9123 - loss: 0.2074 - val_accuracy: 0.8699 - val_f1_score: 0.8823 - val_loss: 0.2411\n",
      "Epoch 24/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8942 - f1_score: 0.9008 - loss: 0.2235 - val_accuracy: 0.8973 - val_f1_score: 0.9059 - val_loss: 0.2386\n",
      "Epoch 25/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8903 - f1_score: 0.8915 - loss: 0.2132 - val_accuracy: 0.8733 - val_f1_score: 0.8833 - val_loss: 0.2443\n",
      "Epoch 26/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8967 - f1_score: 0.8919 - loss: 0.2251 - val_accuracy: 0.8938 - val_f1_score: 0.9028 - val_loss: 0.2403\n",
      "Epoch 27/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9185 - f1_score: 0.9178 - loss: 0.1925 - val_accuracy: 0.8630 - val_f1_score: 0.8757 - val_loss: 0.2432\n",
      "Epoch 28/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8976 - f1_score: 0.9025 - loss: 0.2233 - val_accuracy: 0.8664 - val_f1_score: 0.8796 - val_loss: 0.2399\n",
      "Epoch 29/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8963 - f1_score: 0.9002 - loss: 0.2252 - val_accuracy: 0.8664 - val_f1_score: 0.8800 - val_loss: 0.2488\n",
      "Epoch 30/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9073 - f1_score: 0.9101 - loss: 0.2051 - val_accuracy: 0.8699 - val_f1_score: 0.8820 - val_loss: 0.2396\n",
      "Epoch 31/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8976 - f1_score: 0.8952 - loss: 0.2252 - val_accuracy: 0.8801 - val_f1_score: 0.8917 - val_loss: 0.2397\n",
      "Epoch 32/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8973 - f1_score: 0.8987 - loss: 0.2305 - val_accuracy: 0.8699 - val_f1_score: 0.8820 - val_loss: 0.2401\n",
      "Epoch 33/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9031 - f1_score: 0.9051 - loss: 0.2151 - val_accuracy: 0.8733 - val_f1_score: 0.8883 - val_loss: 0.2385\n",
      "Epoch 34/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8972 - f1_score: 0.8972 - loss: 0.2323 - val_accuracy: 0.8801 - val_f1_score: 0.8903 - val_loss: 0.2380\n",
      "Epoch 35/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9029 - f1_score: 0.9046 - loss: 0.2086 - val_accuracy: 0.8664 - val_f1_score: 0.8790 - val_loss: 0.2408\n",
      "Epoch 36/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8999 - f1_score: 0.9070 - loss: 0.2146 - val_accuracy: 0.8733 - val_f1_score: 0.8855 - val_loss: 0.2413\n",
      "Epoch 37/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9031 - f1_score: 0.9019 - loss: 0.2130 - val_accuracy: 0.8664 - val_f1_score: 0.8719 - val_loss: 0.2483\n",
      "Epoch 38/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8931 - f1_score: 0.8987 - loss: 0.2221 - val_accuracy: 0.8664 - val_f1_score: 0.8791 - val_loss: 0.2432\n",
      "Epoch 39/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9009 - f1_score: 0.9063 - loss: 0.2088 - val_accuracy: 0.8836 - val_f1_score: 0.8934 - val_loss: 0.2388\n",
      "Epoch 40/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9179 - f1_score: 0.9145 - loss: 0.1916 - val_accuracy: 0.8630 - val_f1_score: 0.8738 - val_loss: 0.2469\n",
      "Epoch 41/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - f1_score: 0.9041 - loss: 0.2108 - val_accuracy: 0.8801 - val_f1_score: 0.8888 - val_loss: 0.2349\n",
      "Epoch 42/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8990 - f1_score: 0.9016 - loss: 0.2270 - val_accuracy: 0.8699 - val_f1_score: 0.8852 - val_loss: 0.2385\n",
      "Epoch 43/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8868 - f1_score: 0.8833 - loss: 0.2409 - val_accuracy: 0.8664 - val_f1_score: 0.8789 - val_loss: 0.2437\n",
      "Epoch 44/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9014 - f1_score: 0.9038 - loss: 0.2175 - val_accuracy: 0.8870 - val_f1_score: 0.8966 - val_loss: 0.2434\n",
      "Epoch 45/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9091 - f1_score: 0.9075 - loss: 0.2054 - val_accuracy: 0.8699 - val_f1_score: 0.8838 - val_loss: 0.2400\n",
      "Epoch 46/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9161 - f1_score: 0.9174 - loss: 0.1880 - val_accuracy: 0.8664 - val_f1_score: 0.8787 - val_loss: 0.2471\n",
      "Epoch 47/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8854 - f1_score: 0.8886 - loss: 0.2271 - val_accuracy: 0.8596 - val_f1_score: 0.8738 - val_loss: 0.2561\n",
      "Epoch 48/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8978 - f1_score: 0.9000 - loss: 0.2091 - val_accuracy: 0.8699 - val_f1_score: 0.8805 - val_loss: 0.2435\n",
      "Epoch 49/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9016 - f1_score: 0.9067 - loss: 0.2087 - val_accuracy: 0.8630 - val_f1_score: 0.8771 - val_loss: 0.2452\n",
      "Epoch 50/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8865 - f1_score: 0.8867 - loss: 0.2338 - val_accuracy: 0.8699 - val_f1_score: 0.8834 - val_loss: 0.2383\n",
      "temps dexecution  -15.761082887649536\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time=time.time()\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "end_time=time.time()\n",
    "print(\"temps dexecution \", start_time-end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98b03b10-a89d-471f-805a-403e6fa7de36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joeto\\anaconda3\\envs\\tp\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m3,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,844</span> (15.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,844\u001b[0m (15.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,844</span> (15.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,844\u001b[0m (15.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77fd90ba-bb39-4175-82c2-234f0073ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d74763f-35d7-4cc8-9b36-83e812d98ce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9139 - f1_score: 0.9071 - loss: 0.2144 - val_accuracy: 0.8664 - val_f1_score: 0.8816 - val_loss: 0.2404\n",
      "Epoch 2/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8869 - f1_score: 0.8867 - loss: 0.2574 - val_accuracy: 0.8630 - val_f1_score: 0.8771 - val_loss: 0.2441\n",
      "Epoch 3/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8788 - f1_score: 0.8870 - loss: 0.2473 - val_accuracy: 0.8836 - val_f1_score: 0.8851 - val_loss: 0.2431\n",
      "Epoch 4/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9052 - f1_score: 0.9038 - loss: 0.2281 - val_accuracy: 0.8801 - val_f1_score: 0.8872 - val_loss: 0.2395\n",
      "Epoch 5/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9014 - f1_score: 0.9016 - loss: 0.2216 - val_accuracy: 0.8836 - val_f1_score: 0.8874 - val_loss: 0.2396\n",
      "Epoch 6/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8892 - f1_score: 0.8935 - loss: 0.2295 - val_accuracy: 0.8562 - val_f1_score: 0.8667 - val_loss: 0.2501\n",
      "Epoch 7/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8783 - f1_score: 0.8834 - loss: 0.2485 - val_accuracy: 0.8699 - val_f1_score: 0.8819 - val_loss: 0.2391\n",
      "Epoch 8/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9028 - f1_score: 0.8991 - loss: 0.2103 - val_accuracy: 0.8527 - val_f1_score: 0.8663 - val_loss: 0.2604\n",
      "Epoch 9/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8850 - f1_score: 0.8885 - loss: 0.2314 - val_accuracy: 0.8836 - val_f1_score: 0.8930 - val_loss: 0.2394\n",
      "Epoch 10/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8990 - f1_score: 0.8959 - loss: 0.2221 - val_accuracy: 0.8938 - val_f1_score: 0.9028 - val_loss: 0.2371\n",
      "Epoch 11/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8818 - f1_score: 0.8800 - loss: 0.2443 - val_accuracy: 0.8836 - val_f1_score: 0.8929 - val_loss: 0.2376\n",
      "Epoch 12/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8914 - f1_score: 0.8909 - loss: 0.2256 - val_accuracy: 0.8870 - val_f1_score: 0.8933 - val_loss: 0.2463\n",
      "Epoch 13/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8829 - f1_score: 0.8849 - loss: 0.2449 - val_accuracy: 0.8733 - val_f1_score: 0.8840 - val_loss: 0.2359\n",
      "Epoch 14/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9035 - f1_score: 0.9020 - loss: 0.2160 - val_accuracy: 0.8938 - val_f1_score: 0.9028 - val_loss: 0.2399\n",
      "Epoch 15/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8936 - f1_score: 0.8947 - loss: 0.2328 - val_accuracy: 0.8870 - val_f1_score: 0.8917 - val_loss: 0.2424\n",
      "Epoch 16/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8743 - f1_score: 0.8765 - loss: 0.2686 - val_accuracy: 0.8699 - val_f1_score: 0.8864 - val_loss: 0.2372\n",
      "Epoch 17/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8946 - f1_score: 0.8951 - loss: 0.2326 - val_accuracy: 0.8801 - val_f1_score: 0.8872 - val_loss: 0.2406\n",
      "Epoch 18/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8886 - f1_score: 0.8855 - loss: 0.2307 - val_accuracy: 0.8596 - val_f1_score: 0.8724 - val_loss: 0.2504\n",
      "Epoch 19/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9021 - f1_score: 0.9081 - loss: 0.2088 - val_accuracy: 0.8527 - val_f1_score: 0.8678 - val_loss: 0.2491\n",
      "Epoch 20/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8817 - f1_score: 0.8803 - loss: 0.2537 - val_accuracy: 0.8801 - val_f1_score: 0.8892 - val_loss: 0.2370\n",
      "Epoch 21/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9013 - f1_score: 0.9051 - loss: 0.2108 - val_accuracy: 0.8562 - val_f1_score: 0.8649 - val_loss: 0.2527\n",
      "Epoch 22/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8914 - f1_score: 0.8918 - loss: 0.2248 - val_accuracy: 0.8767 - val_f1_score: 0.8853 - val_loss: 0.2396\n",
      "Epoch 23/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8964 - f1_score: 0.8946 - loss: 0.2272 - val_accuracy: 0.8733 - val_f1_score: 0.8839 - val_loss: 0.2390\n",
      "Epoch 24/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8890 - f1_score: 0.8918 - loss: 0.2176 - val_accuracy: 0.8664 - val_f1_score: 0.8761 - val_loss: 0.2408\n",
      "Epoch 25/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8908 - f1_score: 0.8935 - loss: 0.2167 - val_accuracy: 0.8664 - val_f1_score: 0.8786 - val_loss: 0.2542\n",
      "Epoch 26/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8993 - f1_score: 0.9012 - loss: 0.2229 - val_accuracy: 0.8733 - val_f1_score: 0.8770 - val_loss: 0.2454\n",
      "Epoch 27/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8906 - f1_score: 0.8917 - loss: 0.2374 - val_accuracy: 0.8699 - val_f1_score: 0.8745 - val_loss: 0.2424\n",
      "Epoch 28/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8950 - f1_score: 0.8941 - loss: 0.2305 - val_accuracy: 0.8801 - val_f1_score: 0.8867 - val_loss: 0.2383\n",
      "Epoch 29/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9009 - f1_score: 0.9004 - loss: 0.2242 - val_accuracy: 0.8493 - val_f1_score: 0.8639 - val_loss: 0.2685\n",
      "Epoch 30/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8943 - f1_score: 0.8921 - loss: 0.2305 - val_accuracy: 0.8767 - val_f1_score: 0.8899 - val_loss: 0.2379\n",
      "Epoch 31/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8740 - f1_score: 0.8755 - loss: 0.2634 - val_accuracy: 0.8836 - val_f1_score: 0.8922 - val_loss: 0.2437\n",
      "Epoch 32/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8925 - f1_score: 0.8937 - loss: 0.2364 - val_accuracy: 0.8767 - val_f1_score: 0.8884 - val_loss: 0.2385\n",
      "Epoch 33/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8962 - f1_score: 0.8976 - loss: 0.2308 - val_accuracy: 0.8630 - val_f1_score: 0.8709 - val_loss: 0.2441\n",
      "Epoch 34/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9001 - f1_score: 0.9015 - loss: 0.2217 - val_accuracy: 0.8664 - val_f1_score: 0.8790 - val_loss: 0.2562\n",
      "Epoch 35/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8912 - f1_score: 0.8877 - loss: 0.2356 - val_accuracy: 0.8904 - val_f1_score: 0.8929 - val_loss: 0.2468\n",
      "Epoch 36/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8850 - f1_score: 0.8891 - loss: 0.2397 - val_accuracy: 0.8836 - val_f1_score: 0.8934 - val_loss: 0.2358\n",
      "Epoch 37/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8938 - f1_score: 0.8954 - loss: 0.2450 - val_accuracy: 0.8596 - val_f1_score: 0.8702 - val_loss: 0.2457\n",
      "Epoch 38/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8978 - f1_score: 0.8966 - loss: 0.2230 - val_accuracy: 0.8767 - val_f1_score: 0.8868 - val_loss: 0.2443\n",
      "Epoch 39/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9098 - f1_score: 0.9088 - loss: 0.2160 - val_accuracy: 0.8630 - val_f1_score: 0.8725 - val_loss: 0.2433\n",
      "Epoch 40/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8792 - f1_score: 0.8790 - loss: 0.2405 - val_accuracy: 0.8664 - val_f1_score: 0.8751 - val_loss: 0.2428\n",
      "Epoch 41/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8765 - f1_score: 0.8795 - loss: 0.2396 - val_accuracy: 0.8562 - val_f1_score: 0.8672 - val_loss: 0.2651\n",
      "Epoch 42/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8939 - f1_score: 0.8985 - loss: 0.2363 - val_accuracy: 0.8630 - val_f1_score: 0.8802 - val_loss: 0.2400\n",
      "Epoch 43/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8883 - f1_score: 0.8826 - loss: 0.2372 - val_accuracy: 0.8699 - val_f1_score: 0.8808 - val_loss: 0.2404\n",
      "Epoch 44/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8786 - f1_score: 0.8794 - loss: 0.2449 - val_accuracy: 0.8836 - val_f1_score: 0.8920 - val_loss: 0.2378\n",
      "Epoch 45/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9105 - f1_score: 0.9097 - loss: 0.2198 - val_accuracy: 0.8733 - val_f1_score: 0.8847 - val_loss: 0.2439\n",
      "Epoch 46/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8862 - f1_score: 0.8897 - loss: 0.2287 - val_accuracy: 0.8664 - val_f1_score: 0.8733 - val_loss: 0.2430\n",
      "Epoch 47/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8966 - f1_score: 0.8977 - loss: 0.2267 - val_accuracy: 0.8699 - val_f1_score: 0.8771 - val_loss: 0.2429\n",
      "Epoch 48/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8952 - f1_score: 0.8963 - loss: 0.2184 - val_accuracy: 0.8699 - val_f1_score: 0.8855 - val_loss: 0.2375\n",
      "Epoch 49/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8991 - f1_score: 0.9000 - loss: 0.2047 - val_accuracy: 0.8904 - val_f1_score: 0.9032 - val_loss: 0.2438\n",
      "Epoch 50/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9021 - f1_score: 0.8985 - loss: 0.2275 - val_accuracy: 0.8836 - val_f1_score: 0.8931 - val_loss: 0.2368\n",
      "temps d execution 16.29622769355774\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "time_start=time.time()\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "time_end=time.time()\n",
    "print(\"temps d execution\" ,time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79d739e4-d1c7-476f-89f7-26897736fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, MaxPooling1D, Dropout, BatchNormalization, InputLayer\n",
    "\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8648a82-ab9f-405e-b403-83d18adaffae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │             \u001b[38;5;34m128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m6,208\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m8,224\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m132\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,076</span> (58.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,076\u001b[0m (58.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,884</span> (58.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,884\u001b[0m (58.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.4582 - f1_score: 0.4220 - loss: 1.4670 - val_accuracy: 0.6712 - val_f1_score: 0.0410 - val_loss: 1.0983\n",
      "Epoch 2/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7330 - f1_score: 0.7324 - loss: 0.6347 - val_accuracy: 0.3562 - val_f1_score: 0.1244 - val_loss: 1.0823\n",
      "Epoch 3/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7297 - f1_score: 0.7313 - loss: 0.6295 - val_accuracy: 0.3527 - val_f1_score: 0.2514 - val_loss: 1.0708\n",
      "Epoch 4/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7332 - f1_score: 0.7224 - loss: 0.6070 - val_accuracy: 0.3219 - val_f1_score: 0.2596 - val_loss: 1.0712\n",
      "Epoch 5/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7435 - f1_score: 0.7355 - loss: 0.5886 - val_accuracy: 0.3664 - val_f1_score: 0.2645 - val_loss: 0.9968\n",
      "Epoch 6/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7661 - f1_score: 0.7587 - loss: 0.5596 - val_accuracy: 0.4760 - val_f1_score: 0.3749 - val_loss: 0.9400\n",
      "Epoch 7/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7577 - f1_score: 0.7370 - loss: 0.5401 - val_accuracy: 0.5308 - val_f1_score: 0.3674 - val_loss: 0.8555\n",
      "Epoch 8/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7613 - f1_score: 0.7498 - loss: 0.5371 - val_accuracy: 0.7329 - val_f1_score: 0.6956 - val_loss: 0.6947\n",
      "Epoch 9/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7528 - f1_score: 0.7477 - loss: 0.5398 - val_accuracy: 0.7226 - val_f1_score: 0.6373 - val_loss: 0.6804\n",
      "Epoch 10/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7688 - f1_score: 0.7494 - loss: 0.5120 - val_accuracy: 0.7603 - val_f1_score: 0.7526 - val_loss: 0.6029\n",
      "Epoch 11/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7665 - f1_score: 0.7607 - loss: 0.5279 - val_accuracy: 0.7774 - val_f1_score: 0.7783 - val_loss: 0.5685\n",
      "Epoch 12/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7757 - f1_score: 0.7623 - loss: 0.5064 - val_accuracy: 0.7637 - val_f1_score: 0.7657 - val_loss: 0.5394\n",
      "Epoch 13/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7746 - f1_score: 0.7568 - loss: 0.5096 - val_accuracy: 0.7740 - val_f1_score: 0.7633 - val_loss: 0.5363\n",
      "Epoch 14/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7508 - f1_score: 0.7420 - loss: 0.5037 - val_accuracy: 0.7842 - val_f1_score: 0.7717 - val_loss: 0.4961\n",
      "Epoch 15/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7599 - f1_score: 0.7546 - loss: 0.5164 - val_accuracy: 0.7500 - val_f1_score: 0.7462 - val_loss: 0.5043\n",
      "Epoch 16/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7662 - f1_score: 0.7517 - loss: 0.5106 - val_accuracy: 0.7740 - val_f1_score: 0.7962 - val_loss: 0.4932\n",
      "Epoch 17/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7637 - f1_score: 0.7495 - loss: 0.5129 - val_accuracy: 0.7945 - val_f1_score: 0.7992 - val_loss: 0.4520\n",
      "Epoch 18/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7723 - f1_score: 0.7569 - loss: 0.4939 - val_accuracy: 0.7842 - val_f1_score: 0.7942 - val_loss: 0.4521\n",
      "Epoch 19/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7713 - f1_score: 0.7526 - loss: 0.5002 - val_accuracy: 0.7671 - val_f1_score: 0.7686 - val_loss: 0.4798\n",
      "Epoch 20/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7674 - f1_score: 0.7470 - loss: 0.4937 - val_accuracy: 0.8151 - val_f1_score: 0.8164 - val_loss: 0.4277\n",
      "Epoch 21/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7587 - f1_score: 0.7433 - loss: 0.5231 - val_accuracy: 0.8493 - val_f1_score: 0.8423 - val_loss: 0.4125\n",
      "Epoch 22/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7833 - f1_score: 0.7704 - loss: 0.5052 - val_accuracy: 0.7911 - val_f1_score: 0.8034 - val_loss: 0.4346\n",
      "Epoch 23/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7742 - f1_score: 0.7580 - loss: 0.5219 - val_accuracy: 0.7568 - val_f1_score: 0.7523 - val_loss: 0.4796\n",
      "Epoch 24/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7839 - f1_score: 0.7800 - loss: 0.4595 - val_accuracy: 0.8151 - val_f1_score: 0.8255 - val_loss: 0.4229\n",
      "Epoch 25/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7924 - f1_score: 0.7702 - loss: 0.4805 - val_accuracy: 0.8219 - val_f1_score: 0.8283 - val_loss: 0.4110\n",
      "Epoch 26/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7832 - f1_score: 0.7795 - loss: 0.4582 - val_accuracy: 0.8390 - val_f1_score: 0.8436 - val_loss: 0.4103\n",
      "Epoch 27/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7791 - f1_score: 0.7774 - loss: 0.5150 - val_accuracy: 0.8116 - val_f1_score: 0.8298 - val_loss: 0.4064\n",
      "Epoch 28/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7889 - f1_score: 0.7823 - loss: 0.4667 - val_accuracy: 0.7979 - val_f1_score: 0.8192 - val_loss: 0.4247\n",
      "Epoch 29/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7928 - f1_score: 0.7883 - loss: 0.4494 - val_accuracy: 0.8116 - val_f1_score: 0.8254 - val_loss: 0.4166\n",
      "Epoch 30/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7716 - f1_score: 0.7703 - loss: 0.4798 - val_accuracy: 0.8390 - val_f1_score: 0.8205 - val_loss: 0.4001\n",
      "Epoch 31/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7791 - f1_score: 0.7694 - loss: 0.4632 - val_accuracy: 0.7979 - val_f1_score: 0.8171 - val_loss: 0.4190\n",
      "Epoch 32/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7966 - f1_score: 0.7912 - loss: 0.4379 - val_accuracy: 0.8322 - val_f1_score: 0.8501 - val_loss: 0.3945\n",
      "Epoch 33/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7765 - f1_score: 0.7738 - loss: 0.4869 - val_accuracy: 0.7945 - val_f1_score: 0.7957 - val_loss: 0.4098\n",
      "Epoch 34/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7656 - f1_score: 0.7623 - loss: 0.4575 - val_accuracy: 0.8116 - val_f1_score: 0.8379 - val_loss: 0.3972\n",
      "Epoch 35/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7750 - f1_score: 0.7758 - loss: 0.4790 - val_accuracy: 0.8390 - val_f1_score: 0.8310 - val_loss: 0.3984\n",
      "Epoch 36/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7833 - f1_score: 0.7734 - loss: 0.4673 - val_accuracy: 0.8082 - val_f1_score: 0.8429 - val_loss: 0.4031\n",
      "Epoch 37/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7859 - f1_score: 0.7817 - loss: 0.4416 - val_accuracy: 0.8356 - val_f1_score: 0.8391 - val_loss: 0.4001\n",
      "Epoch 38/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7772 - f1_score: 0.7779 - loss: 0.4634 - val_accuracy: 0.8253 - val_f1_score: 0.8360 - val_loss: 0.3993\n",
      "Epoch 39/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7864 - f1_score: 0.7789 - loss: 0.4586 - val_accuracy: 0.8356 - val_f1_score: 0.8301 - val_loss: 0.4065\n",
      "Epoch 40/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8003 - f1_score: 0.7902 - loss: 0.4210 - val_accuracy: 0.7740 - val_f1_score: 0.8007 - val_loss: 0.4544\n",
      "Epoch 41/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7718 - f1_score: 0.7671 - loss: 0.4819 - val_accuracy: 0.8151 - val_f1_score: 0.8240 - val_loss: 0.4101\n",
      "Epoch 42/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8010 - f1_score: 0.8023 - loss: 0.4626 - val_accuracy: 0.8356 - val_f1_score: 0.8311 - val_loss: 0.4181\n",
      "Epoch 43/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7846 - f1_score: 0.7704 - loss: 0.4584 - val_accuracy: 0.8253 - val_f1_score: 0.8304 - val_loss: 0.4127\n",
      "Epoch 44/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8006 - f1_score: 0.7967 - loss: 0.4410 - val_accuracy: 0.8356 - val_f1_score: 0.8471 - val_loss: 0.3965\n",
      "Epoch 45/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8010 - f1_score: 0.7982 - loss: 0.4455 - val_accuracy: 0.8082 - val_f1_score: 0.8022 - val_loss: 0.4102\n",
      "Epoch 46/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7813 - f1_score: 0.7750 - loss: 0.4659 - val_accuracy: 0.8048 - val_f1_score: 0.8102 - val_loss: 0.4361\n",
      "Epoch 47/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7956 - f1_score: 0.7911 - loss: 0.4378 - val_accuracy: 0.8151 - val_f1_score: 0.8072 - val_loss: 0.4109\n",
      "Epoch 48/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7973 - f1_score: 0.7918 - loss: 0.4574 - val_accuracy: 0.8253 - val_f1_score: 0.8207 - val_loss: 0.3867\n",
      "Epoch 49/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7750 - f1_score: 0.7530 - loss: 0.4738 - val_accuracy: 0.8219 - val_f1_score: 0.8052 - val_loss: 0.3882\n",
      "Epoch 50/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7664 - f1_score: 0.7554 - loss: 0.4766 - val_accuracy: 0.8322 - val_f1_score: 0.8496 - val_loss: 0.3964\n",
      "temp dexecution  30.07066249847412\n"
     ]
    }
   ],
   "source": [
    "model_cnn = Sequential([\n",
    "    InputLayer(input_shape=(24, 1)), \n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(4, activation='softmax') \n",
    "])\n",
    "\n",
    "model_cnn.summary()\n",
    "\n",
    "model_cnn.compile(optimizer=Adam(learning_rate=0.001),  loss='categorical_crossentropy',  metrics=['accuracy',f1_score])\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "history_cnn = model_cnn.fit(X_train_cnn, y_train,   validation_data=(X_test_cnn, y_test),   epochs=50, batch_size=32)\n",
    "end_time=time.time()\n",
    "print(\"temp dexecution \", end_time - start_time )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0befd-0ca9-4a23-a5d0-de4e4bed1c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
