{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dff150d-4e3b-481c-88eb-63239266e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "import files\n",
    "importlib.reload(files)\n",
    "\n",
    "import fonctions\n",
    "importlib.reload(fonctions)\n",
    "\n",
    "from files import *\n",
    "from fonctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a37c0c2-47a9-4c8a-b873-4d9dbe70bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "consommation_chauffage_toulouse = extract_and_concat_consommation(toulouse, column_index=4, prefix=\"consommation_heat_\")\n",
    "consommation_chauffage_zurich = extract_and_concat_consommation(zurich, column_index=4, prefix=\"consommation_heat_\")\n",
    "consommation_chauffage_seville = extract_and_concat_consommation(seville, column_index=4, prefix=\"consommation_heat_\")\n",
    "consommation_climatisation_toulouse = extract_and_concat_consommation(toulouse, column_index=5, prefix=\"consommation_cool_\")\n",
    "consommation_climatisation_zurich = extract_and_concat_consommation(zurich, column_index=5, prefix=\"consommation_cool_\")\n",
    "consommation_climatisation_seville = extract_and_concat_consommation(seville, column_index=5, prefix=\"consommation_cool_\")\n",
    "\n",
    "\n",
    "city_groups = {\n",
    "    \"toulouse\": toulouse_meteo,\n",
    "    \"zurich\": zurich_meteo,\n",
    "    \"seville\": seville_meteo\n",
    "}\n",
    "\n",
    "prefix_column_map = {\n",
    "    \"Text_\": 1,\n",
    "    \"Hum_\": 3,\n",
    "    \"Wind_\": 4,\n",
    "    \"Solar_\": 5,\n",
    "    \"Ground_\": 10\n",
    "}\n",
    "\n",
    "combined_data = extract_and_combine_all(city_groups, prefix_column_map)\n",
    "\n",
    "Text_combined_toulouse = combined_data.get('Text_combined_toulouse')\n",
    "Hum_combined_toulouse = combined_data.get('Hum_combined_toulouse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ada14cb-b43b-4019-81e0-183ab26064ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Fonction pour calculer les métriques ---\n",
    "def compute_metrics(predictions, targets):\n",
    "    mse = torch.mean((predictions - targets) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    mae = torch.mean(torch.abs(predictions - targets))\n",
    "    ss_total = torch.sum((targets - torch.mean(targets)) ** 2)\n",
    "    ss_residual = torch.sum((targets - predictions) ** 2)\n",
    "    r2 = 1 - (ss_residual / ss_total)\n",
    "    cvrmse = (rmse / torch.mean(targets)) * 100\n",
    "    return mae, rmse, mse, r2, cvrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7810ab1-cea5-4584-93fb-41e802a162e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc86a09-b2a1-4729-bd65-6f421711d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# Encodage positionnel pour donner une notion du temps au modèle\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2778f587-641a-4ff2-8732-bd56f28ae866",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTransformerWithDecoder(nn.Module):\n",
    "    def __init__(self, num_features=3, d_model=64, nhead=4, num_layers=2, dim_feedforward=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.input_proj = nn.Linear(num_features, d_model)\n",
    "        self.target_proj = nn.Linear(1, d_model)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        self.pos_decoder = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "\n",
    "        self.output_layer = nn.Linear(d_model, 1)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        # Masque pour empêcher de voir le futur\n",
    "        return torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)\n",
    "\n",
    "    def forward(self, src, tgt, use_mask=False):\n",
    "        # src: (batch, 24, num_features) / tgt: (batch, 24)\n",
    "        src = self.input_proj(src)           # (batch, 24, d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        memory = self.encoder(src)\n",
    "\n",
    "        # Préparer tgt (conso précédente décalée d’un pas)\n",
    "        tgt = tgt.unsqueeze(-1)              # (batch, 24, 1)\n",
    "        tgt = self.target_proj(tgt)          # (batch, 24, d_model)\n",
    "        tgt = self.pos_decoder(tgt)\n",
    "\n",
    "        tgt_mask = self.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device) if use_mask else None\n",
    "\n",
    "        output = self.decoder(tgt, memory, tgt_mask=tgt_mask)\n",
    "        output = self.output_layer(output).squeeze(-1)  # (batch, 24)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0714a9c4-cf26-4c46-bcbd-70a7e98d8c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49194bbc-6e54-411a-80e0-989618dca194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, input_blocks, target_block):\n",
    "        \"\"\"\n",
    "        df : DataFrame avec toutes les variables concaténées par blocs de 24h\n",
    "        input_blocks : liste de tuples (col_start, col_end, day_offset)\n",
    "                       où day_offset = 0 pour aujourd’hui, -1 pour hier, etc.\n",
    "        target_block : tuple (col_start, col_end) pour la target (conso aujourd’hui)\n",
    "        \"\"\"\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "\n",
    "        for i in range(1, len(df)):  # Commencer à 1 pour avoir accès à hier\n",
    "            input_seq = []\n",
    "\n",
    "            for start, end, offset in input_blocks:\n",
    "                row_index = i + offset\n",
    "\n",
    "                # Vérification que row_index est valide\n",
    "                if 0 <= row_index < len(df):\n",
    "                    values = df.iloc[row_index, start:end].values  # shape: (24,)\n",
    "                else:\n",
    "                    values = np.zeros(end - start)  # Utiliser des zéros si l'index est hors limites\n",
    "                input_seq.append(values)\n",
    "\n",
    "            # shape finale: (24, num_features)\n",
    "            input_seq = np.stack(input_seq, axis=1)\n",
    "            self.x.append(input_seq)\n",
    "\n",
    "            # Target: consommation aujourd’hui\n",
    "            target = df.iloc[i, target_block[0]:target_block[1]].values\n",
    "            self.y.append(target)\n",
    "\n",
    "        self.x = torch.tensor(self.x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "\n",
    "def prepare_data(df_scaled, n_features):\n",
    "\n",
    "    input_blocks = []\n",
    "\n",
    "    for i in range(n_features):\n",
    "        start = i * 24\n",
    "        end = (i + 1) * 24\n",
    "\n",
    "        # Aujourd’hui\n",
    "        input_blocks.append((start, end, 0))\n",
    "        # Hier\n",
    "        input_blocks.append((start, end, -1))\n",
    "\n",
    "    # Ajouter la consommation d’hier (toujours la dernière feature)\n",
    "    conso_start = n_features * 24\n",
    "    conso_end = conso_start + 24\n",
    "    input_blocks.append((conso_start, conso_end, -1))\n",
    "    target_block = (df_scaled.shape[1] - 24, df_scaled.shape[1])  \n",
    "    print(input_blocks)\n",
    "    print(target_block)\n",
    "    df_trainval, df_test = train_test_split(df_scaled, test_size=0.2, shuffle=False)\n",
    "    df_train, df_val = train_test_split(df_trainval, test_size=0.1, shuffle=False)\n",
    "    \n",
    "    train_dataset = TimeSeriesDataset(df_train.reset_index(drop=True), input_blocks, target_block)\n",
    "    val_dataset = TimeSeriesDataset(df_val.reset_index(drop=True), input_blocks, target_block)\n",
    "    test_dataset = TimeSeriesDataset(df_test.reset_index(drop=True), input_blocks, target_block)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64cac161-559e-4c8f-ab0e-09a8ea2ae8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 24, 0), (0, 24, -1), (24, 48, -1)]\n",
      "(24, 48)\n"
     ]
    }
   ],
   "source": [
    "df2 = Text_combined_toulouse.copy()\n",
    "df2=pd.concat([df2,consommation_chauffage_toulouse],axis=1).reset_index(drop=True)\n",
    "df2.columns = [f\"col_{i}\" for i in range(df2.shape[1])]\n",
    "\n",
    "target_columns = df2.columns[-24:]  \n",
    "input_columns = df2.columns[:-24]\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = pd.DataFrame(scaler_X.fit_transform(df2[input_columns]), columns=input_columns)\n",
    "y_scaled = pd.DataFrame(scaler_y.fit_transform(df2[target_columns]), columns=target_columns)\n",
    "df_scaled = pd.concat([X_scaled, y_scaled], axis=1)\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader = prepare_data(df_scaled,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "57cc0db2-37cd-47d9-8368-5dbfe437acb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | Train Loss: 0.1175 | MAE: 0.2595 | RMSE: 0.3193 | MSE: 0.1175\n",
      "Epoch [2/10] | Train Loss: 0.0291 | MAE: 0.1289 | RMSE: 0.1688 | MSE: 0.0291\n",
      "Epoch [3/10] | Train Loss: 0.0191 | MAE: 0.1016 | RMSE: 0.1371 | MSE: 0.0191\n",
      "Epoch [4/10] | Train Loss: 0.0163 | MAE: 0.0933 | RMSE: 0.1264 | MSE: 0.0163\n",
      "Epoch [5/10] | Train Loss: 0.0142 | MAE: 0.0852 | RMSE: 0.1176 | MSE: 0.0142\n",
      "→ Validation Loss: 0.0218 | MAE: 0.1165 | RMSE: 0.1459 | MSE: 0.0218 | R2: 0.6213 | CVRMSE: 58.1218\n",
      "Epoch [6/10] | Train Loss: 0.0128 | MAE: 0.0797 | RMSE: 0.1125 | MSE: 0.0128\n",
      "Epoch [7/10] | Train Loss: 0.0114 | MAE: 0.0743 | RMSE: 0.1060 | MSE: 0.0114\n",
      "Epoch [8/10] | Train Loss: 0.0112 | MAE: 0.0740 | RMSE: 0.1046 | MSE: 0.0112\n",
      "Epoch [9/10] | Train Loss: 0.0105 | MAE: 0.0692 | RMSE: 0.1011 | MSE: 0.0105\n",
      "Epoch [10/10] | Train Loss: 0.0102 | MAE: 0.0705 | RMSE: 0.1004 | MSE: 0.0102\n",
      "→ Validation Loss: 0.0181 | MAE: 0.1058 | RMSE: 0.1330 | MSE: 0.0181 | R2: 0.6880 | CVRMSE: 52.7623\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Fonction pour calculer les métriques ---\n",
    "def compute_metrics(predictions, targets):\n",
    "    mse = torch.mean((predictions - targets) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    mae = torch.mean(torch.abs(predictions - targets))\n",
    "    return mae, rmse, mse\n",
    "\n",
    "# --- Fonction pour calculer R2 et CVRMSE (utilisé seulement lors du test/validation) ---\n",
    "def compute_test_metrics(predictions, targets):\n",
    "    mse = torch.mean((predictions - targets) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    mae = torch.mean(torch.abs(predictions - targets))\n",
    "    ss_total = torch.sum((targets - torch.mean(targets)) ** 2)\n",
    "    ss_residual = torch.sum((targets - predictions) ** 2)\n",
    "    r2 = 1 - (ss_residual / (ss_total + 1e-8))\n",
    "    cvrmse = (rmse / (torch.mean(targets)+ 1e-8)) * 100\n",
    "    return mae, rmse, mse, r2, cvrmse\n",
    "\n",
    "# Initialisation du modèle\n",
    "model = TimeSeriesTransformerWithDecoder(\n",
    "    num_features=3,              # 3 features par pas de temps : température, statut, cluster\n",
    "    d_model=64,\n",
    "    nhead=4,\n",
    "    num_layers=2,\n",
    "    dim_feedforward=128,\n",
    "    dropout=0.1\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Optimiseur et fonction de perte\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Boucle d'entraînement\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_mae = 0.0\n",
    "    total_rmse = 0.0\n",
    "    total_mse = 0.0\n",
    "\n",
    "    for batch_idx, (src, tgt) in enumerate(train_loader):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "       \n",
    "        #y_minus_1 = src[:, -1, -1].unsqueeze(1)    \n",
    "        #tgt_input = torch.cat([y_minus_1, tgt[:, :-1]], dim=1) \n",
    "        #tgt_target = tgt \n",
    "\n",
    "        \n",
    "        batch_size, pred_len = tgt.size()  # pred_len = 24\n",
    "        tgt_target = tgt \n",
    "        decoder_input = src[:, -1, -1].unsqueeze(1)  # y_{t-1}, [batch, 1]\n",
    "\n",
    "        predictions = []\n",
    "        for t in range(pred_len):\n",
    "            out = model(src, decoder_input, use_mask=False)         # out: [batch, t+1]\n",
    "            next_val = out[:, -1:]                  # dernière valeur prédite [batch, 1]\n",
    "            predictions.append(next_val)\n",
    "            decoder_input = torch.cat([decoder_input, next_val], dim=1)  # accumulate\n",
    "\n",
    "        output = torch.cat(predictions, dim=1)  # [batch, 24]\n",
    "\n",
    "        \n",
    "        \n",
    "        loss = criterion(output, tgt_target)\n",
    "        mae, rmse, mse = compute_metrics(output, tgt_target)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_mae += mae.item()\n",
    "        total_rmse += rmse.item()\n",
    "        total_mse += mse.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Affichage des métriques d'entraînement\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {total_loss / len(train_loader):.4f} | \"\n",
    "          f\"MAE: {total_mae / len(train_loader):.4f} | RMSE: {total_rmse / len(train_loader):.4f} | \"\n",
    "          f\"MSE: {total_mse / len(train_loader):.4f}\")\n",
    "\n",
    "        # Validation\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_mae = 0.0\n",
    "        val_rmse = 0.0\n",
    "        val_mse = 0.0\n",
    "        val_r2 = 0.0\n",
    "        val_cvrmse = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (src, tgt) in enumerate(val_loader):\n",
    "                src, tgt = src.to(device), tgt.to(device)\n",
    "    \n",
    "                #y_minus_1 = src[:, -1, -1].unsqueeze(1) \n",
    "                #tgt_input = torch.cat([y_minus_1, tgt[:, :-1]], dim=1) \n",
    "                #tgt_target = tgt \n",
    "                #output = model(src, tgt_input)\n",
    "                batch_size, pred_len = tgt.size()  # pred_len = 24\n",
    "                tgt_target = tgt\n",
    "                decoder_input = src[:, -1, -1].unsqueeze(1)  # y_{t-1}, [batch, 1]\n",
    "\n",
    "                predictions = []\n",
    "                for t in range(pred_len):\n",
    "                    out = model(src, decoder_input, use_mask=False)         # out: [batch, t+1]\n",
    "                    next_val = out[:, -1:]                  # dernière valeur prédite [batch, 1]\n",
    "                    predictions.append(next_val)\n",
    "                    decoder_input = torch.cat([decoder_input, next_val], dim=1)  # accumulate\n",
    "\n",
    "                output = torch.cat(predictions, dim=1)  # [batch, 24]\n",
    "        \n",
    "                \n",
    "    \n",
    "                # Inverser la normalisation pour R2 et CVRMSE\n",
    "                output_unscaled = scaler_y.inverse_transform(output.cpu().numpy())  # Convertir en numpy\n",
    "                tgt_unscaled = scaler_y.inverse_transform(tgt_target.cpu().numpy())\n",
    "    \n",
    "                # Calcul des métriques standards (MAE, RMSE, MSE) sur les valeurs normalisées\n",
    "                loss = criterion(output, tgt_target)\n",
    "                mae, rmse, mse = compute_metrics(output, tgt_target)\n",
    "    \n",
    "                # Calcul de R2 et CVRMSE après inverse de la normalisation\n",
    "                # Inverser la normalisation pour R2 et CVRMSE\n",
    "                ss_total = torch.sum((torch.tensor(tgt_unscaled).to(device) - torch.mean(torch.tensor(tgt_unscaled).to(device))) ** 2)\n",
    "                ss_residual = torch.sum((torch.tensor(tgt_unscaled).to(device) - torch.tensor(output_unscaled).to(device)) ** 2)\n",
    "                r2 = 1 - (ss_residual / (ss_total ))\n",
    "                rmse_unscaled = torch.sqrt(torch.mean((torch.tensor(output_unscaled).to(device) - torch.tensor(tgt_unscaled).to(device)) ** 2))\n",
    "                cvrmse = (rmse_unscaled / (torch.mean(torch.tensor(tgt_unscaled).to(device)) )) * 100\n",
    "    \n",
    "                # Mise à jour des métriques de validation\n",
    "                val_loss += loss.item()\n",
    "                val_mae += mae.item()\n",
    "                val_rmse += rmse.item()\n",
    "                val_mse += mse.item()\n",
    "                val_r2 += r2.item()\n",
    "                val_cvrmse += cvrmse.item()\n",
    "    \n",
    "        # Affichage des métriques de validation\n",
    "        print(f\"→ Validation Loss: {val_loss / len(val_loader):.4f} | \"\n",
    "              f\"MAE: {val_mae / len(val_loader):.4f} | RMSE: {val_rmse / len(val_loader):.4f} | \"\n",
    "              f\"MSE: {val_mse / len(val_loader):.4f} | R2: {val_r2 / len(val_loader):.4f} | \"\n",
    "              f\"CVRMSE: {val_cvrmse / len(val_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4af51228-89eb-4a4f-a2f9-defeb74f8c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST SET RESULTS ===\n",
      "Test Loss: 0.0037 | MAE: 146.0478 | RMSE: 181.6176 | MSE: 77264.1401 | R2: -16859116392354.9043 | CVRMSE: 618380625232.9381\n"
     ]
    }
   ],
   "source": [
    "# --- Phase de test ---\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_mae = 0.0\n",
    "test_rmse = 0.0\n",
    "test_mse = 0.0\n",
    "test_r2 = 0.0\n",
    "test_cvrmse = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (src, tgt) in enumerate(test_loader):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        tgt_target = tgt  # [batch, 24]\n",
    "        batch_size, pred_len = tgt.size()\n",
    "\n",
    "        decoder_input = src[:, -1, -1].unsqueeze(1)  # y_{t-1}, shape: [batch, 1]\n",
    "        predictions = []\n",
    "\n",
    "        for t in range(pred_len):\n",
    "            out = model(src, decoder_input, use_mask=False)\n",
    "            next_val = out[:, -1:]  # [batch, 1]\n",
    "            predictions.append(next_val)\n",
    "            decoder_input = torch.cat([decoder_input, next_val], dim=1)\n",
    "\n",
    "        output = torch.cat(predictions, dim=1)  # [batch, 24]\n",
    "\n",
    "        # Inverse transform pour métriques réelles\n",
    "        output_unscaled = scaler_y.inverse_transform(output.cpu().numpy())\n",
    "        tgt_unscaled = scaler_y.inverse_transform(tgt_target.cpu().numpy())\n",
    "\n",
    "        # Conversion vers tensors\n",
    "        output_unscaled_tensor = torch.tensor(output_unscaled).to(device)\n",
    "        tgt_unscaled_tensor = torch.tensor(tgt_unscaled).to(device)\n",
    "\n",
    "        # Calcul des métriques normalisées (pour suivi)\n",
    "        loss = criterion(output, tgt_target)\n",
    "        mae, rmse, mse, r2, cvrmse = compute_test_metrics(output_unscaled_tensor, tgt_unscaled_tensor)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        test_mae += mae.item()\n",
    "        test_rmse += rmse.item()\n",
    "        test_mse += mse.item()\n",
    "        test_r2 += r2.item()\n",
    "        test_cvrmse += cvrmse.item()\n",
    "\n",
    "print(f\"\\n=== TEST SET RESULTS ===\")\n",
    "print(f\"Test Loss: {test_loss / len(test_loader):.4f} | \"\n",
    "      f\"MAE: {test_mae / len(test_loader):.4f} | RMSE: {test_rmse / len(test_loader):.4f} | \"\n",
    "      f\"MSE: {test_mse / len(test_loader):.4f} | R2: {test_r2 / len(test_loader):.4f} | \"\n",
    "      f\"CVRMSE: {test_cvrmse / len(test_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8b2cd-a0f2-4f4e-b5e6-979f8f394499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
